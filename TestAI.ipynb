{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "TestAI.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhi-lejon/Neural-Networks/blob/master/TestAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOqRWcvJB8q4"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding = 'same', kernel_initializer=\"he_normal\",\n",
        "                 input_shape = (img_rows, img_cols, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), padding = \"same\", kernel_initializer=\"he_normal\", \n",
        "                 input_shape = (img_rows, img_cols, 3)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Block #2: second CONV => RELU => CONV => RELU => POOL\n",
        "# layer set\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Block #3: third CONV => RELU => CONV => RELU => POOL\n",
        "# layer set\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Block #4: third CONV => RELU => CONV => RELU => POOL\n",
        "# layer set\n",
        "model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Block #5: first set of FC => RELU layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Block #6: second set of FC => RELU layers\n",
        "model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Block #7: softmax classifier\n",
        "model.add(Dense(num_classes, kernel_initializer=\"he_normal\"))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWhSitRLB8q8"
      },
      "source": [
        "rom keras.optimizers import RMSprop, SGD, Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "                     \n",
        "checkpoint = ModelCheckpoint(\"E:\\\\my deep learning projects\\\\face recognization\\\\25. Face Recognition\\\\face_recognition_friends_vgg.h5\",\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)\n",
        "\n",
        "earlystop = EarlyStopping(monitor = 'val_loss', \n",
        "                          min_delta = 0, \n",
        "                          patience = 3,\n",
        "                          verbose = 1,\n",
        "                          restore_best_weights = True)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 3, verbose = 1, min_delta = 0.0001)\n",
        "\n",
        "# we put our call backs into a callback list\n",
        "callbacks = [earlystop, checkpoint, reduce_lr]\n",
        "\n",
        "# We use a very small learning rate \n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.01),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "nb_train_samples = 2663\n",
        "nb_validation_samples = 955\n",
        "epochs = 1\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch = nb_train_samples // batch_size,\n",
        "    epochs = epochs,\n",
        "    callbacks = callbacks,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = nb_validation_samples // batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5ch4WInB8q_"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "face_classes = {0: 'Chandler', 1: 'Joey', 2: 'Pheobe', 3: 'Rachel'}\n",
        "\n",
        "def draw_label(image, point, label, font=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "               font_scale=0.8, thickness=1):\n",
        "    size = cv2.getTextSize(label, font, font_scale, thickness)[0]\n",
        "    x, y = point\n",
        "    cv2.rectangle(image, (x, y - size[1]), (x + size[0], y), (255, 0, 0), cv2.FILLED)\n",
        "    cv2.putText(image, label, point, font, font_scale, (255, 255, 255), thickness, lineType=cv2.LINE_AA)\n",
        "    \n",
        "margin = 0.2\n",
        "# load model and weights\n",
        "img_size = 64\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "cap = cv2.VideoCapture(\"E:\\\\my deep learning projects\\\\face recognization\\\\25. Face Recognition\\\\testfriends.mp4\")\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    frame = cv2.resize(frame, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
        "    preprocessed_faces = []           \n",
        " \n",
        "    input_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    img_h, img_w, _ = np.shape(input_img)\n",
        "    detected = detector(frame, 1)\n",
        "    faces = np.empty((len(detected), img_size, img_size, 3))\n",
        "    \n",
        "    preprocessed_faces_emo = []\n",
        "    if len(detected) > 0:\n",
        "        for i, d in enumerate(detected):\n",
        "            x1, y1, x2, y2, w, h = d.left(), d.top(), d.right() + 1, d.bottom() + 1, d.width(), d.height()\n",
        "            xw1 = max(int(x1 - margin * w), 0)\n",
        "            yw1 = max(int(y1 - margin * h), 0)\n",
        "            xw2 = min(int(x2 + margin * w), img_w - 1)\n",
        "            yw2 = min(int(y2 + margin * h), img_h - 1)\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "            # cv2.rectangle(img, (xw1, yw1), (xw2, yw2), (255, 0, 0), 2)\n",
        "            #faces[i, :, :, :] = cv2.resize(frame[yw1:yw2 + 1, xw1:xw2 + 1, :], (img_size, img_size))\n",
        "            face =  frame[yw1:yw2 + 1, xw1:xw2 + 1, :]\n",
        "            face = cv2.resize(face, (48, 48), interpolation = cv2.INTER_AREA)\n",
        "            face = face.astype(\"float\") / 255.0\n",
        "            face = img_to_array(face)\n",
        "            face = np.expand_dims(face, axis=0)\n",
        "            preprocessed_faces.append(face)\n",
        "\n",
        "        # make a prediction for Emotion \n",
        "        face_labels = []\n",
        "        for i, d in enumerate(detected):\n",
        "            preds = classifier.predict(preprocessed_faces[i])[0]\n",
        "            face_labels.append(face_classes[preds.argmax()])\n",
        "        \n",
        "        # draw results\n",
        "        for i, d in enumerate(detected):\n",
        "            label = \"{}\".format(face_labels[i])\n",
        "            draw_label(frame, (d.left(), d.top()), label)\n",
        "\n",
        "    cv2.imshow(\"Friend Character Identifier\", frame)\n",
        "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfmgFrw-B8rB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}